{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression (3) - gradient descent.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paryoja/deeplearningstudy/blob/master/Regression_(3)_gradient_descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ZKnXwQQS1QNL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tensorflow 내에서 transpose를 하기 위해서는\n",
        "\n",
        "tf.transpose 함수를 이용 할 수 있다.\n",
        "\n",
        "\n",
        "\n",
        "행 벡터나 열 백터를 transpose하는 것은 reshape 하는 것과 같다\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "QRynfp1W06fD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "_x1 = np.arange(20, dtype=np.float32)\n",
        "_x2 = np.arange(20, dtype=np.float32)\n",
        "\n",
        "dx1 = []\n",
        "dx2 = []\n",
        "dy = []\n",
        "for x1 in _x1:\n",
        "    for x2 in _x2:\n",
        "        dx1.append(x1)\n",
        "        dx2.append(x2)\n",
        "        dy.append(x1 * 3 + x2 * 5 - 1 + np.random.normal(0, 5))\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(dx1, dx2, dy, c='r')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "w1 = tf.Variable(tf.random_normal([1]), name='w1')\n",
        "w2 = tf.Variable(tf.random_normal([1]), name='w2')\n",
        "b = tf.Variable(tf.zeros([1]), name='b')\n",
        "\n",
        "x1 = tf.constant(dx1)\n",
        "x2 = tf.constant(dx2)\n",
        "y = tf.constant(dy)\n",
        "\n",
        "# 모델을 만드는 핵심 부분\n",
        "hypothesis = w1 * x1 + w2 * x2 + b\n",
        "\n",
        "# loss는 squared error sum을 사용했다\n",
        "loss = tf.reduce_sum(tf.square(hypothesis - y))\n",
        "\n",
        "learning_rate = 0.00001\n",
        "\n",
        "\n",
        "# 이부분을 사용하지 말자\n",
        "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
        "#train_op = optimizer.minimize(loss)\n",
        "\n",
        "# 슬라이드를 참고해서 구현해보면,\n",
        "# https://docs.google.com/presentation/d/1T4QqHUi_dHnpcbIwAqtxedj657fwm_nDDneYTMHYEpM/edit?usp=sharing\n",
        "\n",
        "grad_w1 = tf.reduce_sum(2*(w1 * x1 + w2 * x2 + b - y) * x1)\n",
        "grad_w2 = tf.reduce_sum(2*(w1 * x1 + w2 * x2 + b - y) * x2)\n",
        "grad_b =  tf.reduce_sum(2*(w1 * x1 + w2 * x2 + b - y))\n",
        "\n",
        "\n",
        "\n",
        "update_w1 = tf.assign(w1, w1 - learning_rate * grad_w1)\n",
        "update_w2 = tf.assign(w2, w2 - learning_rate * grad_w2)\n",
        "update_b = tf.assign(b, b - learning_rate * grad_b)\n",
        "\n",
        "\n",
        "train_op = [update_w1, update_w2, update_b]\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for i in range(100):\n",
        "  # _ 도 합법적인 변수의 이름이다.\n",
        "  # 파이썬에서는 무시할 변수가 있다면 그 변수의 이름 _로 한다\n",
        "  # train_op 의 sess.run 결과는 None이기 때문에 굳이 필요 없다\n",
        "  l, _ = sess.run([loss, train_op])\n",
        "  \n",
        "  print('epoch',i, 'loss', l)\n",
        "\n",
        "w1_value, w2_value, b_value = sess.run([w1, w2, b])\n",
        "\n",
        "prediction = w1_value * dx1 + w2_value * dx2 + b_value\n",
        "\n",
        "\n",
        "if np.isnan(prediction[0]):\n",
        "  print(\"Prediction is Nan!!\")\n",
        "else:  \n",
        "  fig = plt.figure()\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "  ax.scatter(dx1, dx2, dy, c='r')\n",
        "  ax.scatter(dx1, dx2, prediction)\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vyap0jCX1D_6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}