{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression (1) - Linear Regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paryoja/deeplearningstudy/blob/master/Regression_(1)_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2Ucw219Dl_qv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Regression\n",
        "다음과 같은 데이터를 사용해보자"
      ]
    },
    {
      "metadata": {
        "id": "e4gIjbOfl_qy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.arange(10, dtype=np.float32)\n",
        "\n",
        "y = x + np.random.normal(0, 0.5, 10)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "plt.plot(x, y, '.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jTb-s6h1l_q4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "이 데이터를 fitting 하는 linear model을 구현해보자"
      ]
    },
    {
      "metadata": {
        "id": "M95JB-1pl_q7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "input_x = tf.constant(x, dtype=tf.float32)\n",
        "target_y = tf.constant(y, dtype=tf.float32)\n",
        "\n",
        "w = tf.Variable(tf.random_normal([1]))\n",
        "b = tf.Variable(0.0)\n",
        "\n",
        "hypothesis = w * input_x + b\n",
        "\n",
        "\n",
        "loss = tf.reduce_sum(tf.square(hypothesis - target_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oUFGBQgzl_rA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Gradient descent 로 optimize 해보자\n",
        "\n",
        "tf.train.GradientDescentOptimizer\n",
        "\n",
        "class의 instant로 할 수 있다"
      ]
    },
    {
      "metadata": {
        "id": "C7ZOUFH8l_rC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
        "\n",
        "train_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ajuhYJbl_rI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "train_op 에는 먼저\n",
        "\n",
        "1. loss의 변수에 대한 gradient를 계산한다\n",
        "\n",
        "2. 변수 w를 w - learning_rate * gradient_of_w 로 업데이트 한다 (b도 마찬가지)\n",
        "\n",
        "두가지로 이루어져 있다\n",
        "\n",
        "여기서 다시 tensorflow는 게으름을 생각해보자.\n",
        "\n",
        "여기까지는 어떻게 할 거다 만 정의한 것이고,\n",
        "\n",
        "실제로 수행은 sess 하나가 필요하다"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "NU-p6skNl_rK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "\n",
        "sess.run(train_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kf9_8JHJl_rM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "굉장한 에러가 났다\n",
        "\n",
        "무엇이 빠졌는지 다음 셀에 채워보자"
      ]
    },
    {
      "metadata": {
        "id": "sMAGPdSrl_rN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session()\n",
        "\n",
        "## 여기에 필요한 연산을 넣어보자\n",
        "\n",
        "print(sess.run([loss, w, b]))\n",
        "sess.run(train_op)\n",
        "print(sess.run([loss, w, b]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BLwUeYMgl_rQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "한번 수행하면 어떻게 됬는지 보자 w와 b값은 어떻게 됬을까?\n",
        "\n",
        "우리가 예상한 값에서 아직 많이 멀다.\n",
        "\n",
        "한 백번정도 업데이트를 시켜보자"
      ]
    },
    {
      "metadata": {
        "id": "gFFLHsqOl_rR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "    sess.run(train_op)\n",
        "    print(sess.run([loss, w, b]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g1P0Buocl_rU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "찾아진 w 와 b로 그래프를 그려보자."
      ]
    },
    {
      "metadata": {
        "id": "0C2FIjYjl_rV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final_w, final_b = sess.run([w, b])\n",
        "\n",
        "plt.plot(x, y, '.')\n",
        "plt.plot(x, final_w * x + final_b, '.')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x, y, '.')\n",
        "\n",
        "new_x = np.linspace(0, 10, 1000)\n",
        "plt.plot(new_x, final_w * new_x + final_b, '.')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AOfgULbQl_rY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 실습\n",
        "\n",
        "2차원 데이터의 linear regression을 해보자\n",
        "\n",
        "입력은 dx1, dx2\n",
        "\n",
        "맞춰야 하는 값은 dy 이다"
      ]
    },
    {
      "metadata": {
        "id": "q-crm_o0l_rZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_x1 = np.arange(20)\n",
        "_x2 = np.arange(20)\n",
        "\n",
        "dx1 = []\n",
        "dx2 = []\n",
        "dy = []\n",
        "for x1 in _x1:\n",
        "    for x2 in _x2:\n",
        "        dx1.append(x1)\n",
        "        dx2.append(x2)\n",
        "        dy.append(x1 * 3 + x2 * 5 - 1 + np.random.normal(0, 5))\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(dx1, dx2, dy, c='r')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O6nAJrXil_rd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 과제\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
        "\n",
        "train_op = optimizer.minimize(loss)\n",
        "\n",
        "없이\n",
        "\n",
        "실제로 gradient descent를\n",
        "\n",
        "손으로 미분한 것과\n",
        "\n",
        "tf.assign을 활용하여 구현해보자\n",
        "\n",
        "참고자료\n",
        "\n",
        "https://docs.google.com/presentation/d/1T4QqHUi_dHnpcbIwAqtxedj657fwm_nDDneYTMHYEpM/edit?usp=sharing"
      ]
    },
    {
      "metadata": {
        "id": "5GO-dihMl_rd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}